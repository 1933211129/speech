{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "40c63738-5049-45d8-9686-2bfd27750019",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import BertTokenizerFast, BertForSequenceClassification\n",
    "import os\n",
    "import wave\n",
    "import os\n",
    "import joblib\n",
    "import numpy as np\n",
    "import wave\n",
    "from train import getFeature\n",
    "\n",
    "\n",
    "class text_audio_emo_predict:\n",
    "    def __init__(self, audio_name):\n",
    "        self.audio_name = audio_name\n",
    "\n",
    "    def text_predict(self, texts):\n",
    "        '''文本预测'''\n",
    "        # 设置使用的设备\n",
    "        device = torch.device('cpu')\n",
    "\n",
    "        # 初始化tokenizer和模型\n",
    "        tokenizer = BertTokenizerFast.from_pretrained('bert-base-chinese')\n",
    "        model = BertForSequenceClassification.from_pretrained(\"E:/code_test/text_model/ColabFiles\", num_labels=3) # 修改为你的模型文件路径\n",
    "        model.to(device)\n",
    "        # 输入：一系列的文本\n",
    "        # 输出：二维列表，每个子列表包含两个元素，第一个元素是预测结果，第二个元素是预测概率\n",
    "        label_map = {0: \"negative\", 1: \"neutral\", 2: \"positive\"}\n",
    "        encodings = tokenizer(texts, truncation=True, padding=True, max_length=512, return_tensors=\"pt\").to(device)\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**encodings)\n",
    "            logits = outputs.logits\n",
    "            probs = torch.nn.functional.softmax(logits, dim=-1)\n",
    "            predictions = torch.argmax(logits, dim=-1)\n",
    "        \n",
    "        result = []\n",
    "        for i in range(len(texts)):\n",
    "            result.append([label_map[predictions[i].item()], probs[i][predictions[i]].item()])\n",
    "        return result\n",
    "    \n",
    "    def audio_predict(self, audio_list):\n",
    "        \n",
    "        # 加载模型\n",
    "        model = joblib.load(\"classfier.m\")\n",
    "\n",
    "        labels = np.array(['angry', 'fear', 'happy', 'neutral', 'sad', 'surprise'])\n",
    "        emotion_label_list = []\n",
    "        emotion_value_list = []\n",
    "    \n",
    "        for wav_path in audio_list:\n",
    "            print(wav_path)\n",
    "            f = wave.open(wav_path, 'rb')\n",
    "            data_feature = getFeature(wav_path, 48)\n",
    "\n",
    "            probability_data = model.predict_proba([data_feature])[0] # 获取概率列表\n",
    "            max_probability_index = np.argmax(probability_data) # 最大概率的坐标\n",
    "            max_probability = probability_data[max_probability_index] # 最大概率值\n",
    "            emotion_label = labels[max_probability_index]  # 最终的表情\n",
    "            emotion_label_list.append(emotion_label)\n",
    "            emotion_value_list.append(max_probability)\n",
    "            combined_list = [[emotion, value] for emotion, value in zip(emotion_label_list, emotion_value_list)]\n",
    "            f.close()\n",
    "\n",
    "        return combined_list\n",
    "\n",
    "    def split_wav_file(self, segment_length=5):\n",
    "        '''音频5s分割'''\n",
    "        # 打开输入的 WAV 文件\n",
    "        with wave.open(self.audio_name, 'rb') as wav_file:\n",
    "            frame_rate = wav_file.getframerate()  # 采样率\n",
    "            num_frames = wav_file.getnframes()  # 音频帧数\n",
    "            channels = wav_file.getnchannels()  # 声道数\n",
    "            bytes_per_sample = wav_file.getsampwidth()  # 每个采样的字节数\n",
    "\n",
    "            segment_frames = segment_length * frame_rate  # 每个分割片段的帧数\n",
    "\n",
    "            # 计算总的分割片段数\n",
    "            total_segments = num_frames // segment_frames\n",
    "\n",
    "            # 创建一个目录来存储分割后的音频文件\n",
    "            output_dir = 'segmented_audio'\n",
    "            os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "            segment_names = []\n",
    "\n",
    "            # 将音频文件分割为片段\n",
    "            for segment_index in range(total_segments):\n",
    "                segment_start = segment_index * segment_frames\n",
    "                segment_end = segment_start + segment_frames\n",
    "\n",
    "                # 从输入的 WAV 文件中读取分割片段的帧\n",
    "                wav_file.setpos(segment_start)\n",
    "                segment_data = wav_file.readframes(segment_frames)\n",
    "\n",
    "                # 创建一个新的 WAV 文件来存储分割片段\n",
    "                segment_filename = f'{output_dir}/segment_{segment_index + 1}.wav'\n",
    "                segment_names.append(segment_filename)\n",
    "\n",
    "                with wave.open(segment_filename, 'wb') as segment_wav:\n",
    "                    segment_wav.setnchannels(channels)\n",
    "                    segment_wav.setsampwidth(bytes_per_sample)\n",
    "                    segment_wav.setframerate(frame_rate)\n",
    "                    segment_wav.writeframes(segment_data)\n",
    "        return segment_names\n",
    "    ###############################################列表分割#####################\n",
    "    def list_split(self, my_list):\n",
    "        new_list = []\n",
    "        # 判断列表长度是否大于 10\n",
    "        if len(my_list) > 10:\n",
    "            # 使用切片进行分割\n",
    "            for i in range(0, len(my_list), 10):\n",
    "                sub_list = my_list[i:i + 10]\n",
    "                new_list.append(sub_list)\n",
    "            return new_list\n",
    "        else:\n",
    "            new_list.append(my_list)\n",
    "            return new_list\n",
    "\n",
    "    def get_token(self):\n",
    "        import base64\n",
    "        import hashlib\n",
    "        import hmac\n",
    "        import requests\n",
    "        import time\n",
    "        import uuid\n",
    "        from urllib import parse\n",
    "        class AccessToken:\n",
    "            @staticmethod\n",
    "            def _encode_text(text):\n",
    "                encoded_text = parse.quote_plus(text)\n",
    "                return encoded_text.replace('+', '%20').replace('*', '%2A').replace('%7E', '~')\n",
    "            @staticmethod\n",
    "            def _encode_dict(dic):\n",
    "                keys = dic.keys()\n",
    "                dic_sorted = [(key, dic[key]) for key in sorted(keys)]\n",
    "                encoded_text = parse.urlencode(dic_sorted)\n",
    "                return encoded_text.replace('+', '%20').replace('*', '%2A').replace('%7E', '~')\n",
    "            @staticmethod\n",
    "            def create_token(access_key_id, access_key_secret):\n",
    "                parameters = {'AccessKeyId': access_key_id,\n",
    "                            'Action': 'CreateToken',\n",
    "                            'Format': 'JSON',\n",
    "                            'RegionId': 'cn-shanghai',\n",
    "                            'SignatureMethod': 'HMAC-SHA1',\n",
    "                            'SignatureNonce': str(uuid.uuid1()),\n",
    "                            'SignatureVersion': '1.0',\n",
    "                            'Timestamp': time.strftime(\"%Y-%m-%dT%H:%M:%SZ\", time.gmtime()),\n",
    "                            'Version': '2019-02-28'}\n",
    "                # 构造规范化的请求字符串\n",
    "                query_string = AccessToken._encode_dict(parameters)\n",
    "                # print('规范化的请求字符串: %s' % query_string)\n",
    "                # 构造待签名字符串\n",
    "                string_to_sign = 'GET' + '&' + AccessToken._encode_text('/') + '&' + AccessToken._encode_text(query_string)\n",
    "                # print('待签名的字符串: %s' % string_to_sign)\n",
    "                # 计算签名\n",
    "                secreted_string = hmac.new(bytes(access_key_secret + '&', encoding='utf-8'),\n",
    "                                        bytes(string_to_sign, encoding='utf-8'),\n",
    "                                        hashlib.sha1).digest()\n",
    "                signature = base64.b64encode(secreted_string)\n",
    "                # print('签名: %s' % signature)\n",
    "                # 进行URL编码\n",
    "                signature = AccessToken._encode_text(signature)\n",
    "                # print('URL编码后的签名: %s' % signature)\n",
    "                # 调用服务\n",
    "                full_url = 'http://nls-meta.cn-shanghai.aliyuncs.com/?Signature=%s&%s' % (signature, query_string)\n",
    "                # print('url: %s' % full_url)\n",
    "                # 提交HTTP GET请求\n",
    "                response = requests.get(full_url, verify=False)\n",
    "                if response.ok:\n",
    "                    root_obj = response.json()\n",
    "                    key = 'Token'\n",
    "                    if key in root_obj:\n",
    "                        token = root_obj[key]['Id']\n",
    "                        expire_time = root_obj[key]['ExpireTime']\n",
    "                        return token, expire_time\n",
    "                # print(response.text)\n",
    "                return None, None\n",
    "        # 用户信息\n",
    "        access_key_id = 'LTAI5tDmPLjzT4yJ9xaNPu34'\n",
    "        access_key_secret = '2rG2MD6hXanAdpeyOADtkLl2vLhbpv'\n",
    "        token, expire_time = AccessToken.create_token(access_key_id, access_key_secret)\n",
    "        return token\n",
    "    ######################################转写测试函数###########################\n",
    "    def ali_audio_rec(self, audioFiles):\n",
    "        import threading\n",
    "        import http.client\n",
    "        import json\n",
    "        \n",
    "        def process(request, audioFile):\n",
    "            with open(audioFile, mode='rb') as f:\n",
    "                audioContent = f.read()\n",
    "            host = 'nls-gateway.cn-shanghai.aliyuncs.com'\n",
    "            httpHeaders = {\n",
    "                'Content-Length': len(audioContent)\n",
    "            }\n",
    "            conn = http.client.HTTPConnection(host)\n",
    "            conn.request(method='POST', url=request, body=audioContent, headers=httpHeaders)\n",
    "            response = conn.getresponse()\n",
    "            body = response.read()\n",
    "            try:\n",
    "                body = json.loads(body)\n",
    "                status = body['status']\n",
    "                if status == 20000000:\n",
    "                    result = body['result']\n",
    "                else:\n",
    "                    print('Recognizer failed!')\n",
    "            except ValueError:\n",
    "                print('The response is not json format string')\n",
    "            conn.close()\n",
    "            return body\n",
    "\n",
    "        def process_audio_file(audioFile, result_dict):\n",
    "            request = url + '?appkey=' + appKey\n",
    "            request = request + '&token=' + token\n",
    "            request = request + '&format=' + format\n",
    "            request = request + '&sample_rate=' + str(sampleRate)\n",
    "            result = process(request, audioFile)\n",
    "            try:\n",
    "                text = []\n",
    "                tmp = result['flash_result']['sentences']\n",
    "                for i in range(len(tmp)):\n",
    "                    text.append(tmp[i]['text'])\n",
    "                content = ''.join(text)\n",
    "                result_dict[audioFile] = content\n",
    "                \n",
    "            except KeyError:\n",
    "                print(f\"Warning: 'flash_result' key not found in result for file: {audioFile}\")\n",
    "\n",
    "        appKey = 'PStE5j0aeBM2SRCO'\n",
    "        token = self.get_token()\n",
    "\n",
    "        url = 'https://nls-gateway.cn-shanghai.aliyuncs.com/stream/v1/FlashRecognizer'\n",
    "\n",
    "        format = 'wav'\n",
    "        sampleRate = 16000\n",
    "        enablePunctuationPrediction = True\n",
    "        enableInverseTextNormalization = True\n",
    "        enableVoiceDetection = False\n",
    "\n",
    "        threads = []\n",
    "        result_dict = {}\n",
    "\n",
    "        for audioFile in audioFiles:\n",
    "            for audio in audioFile:\n",
    "                thread = threading.Thread(target=process_audio_file, args=(audio, result_dict))\n",
    "                thread.start()\n",
    "                threads.append(thread)\n",
    "\n",
    "            for thread in threads:\n",
    "                thread.join()\n",
    "\n",
    "        return result_dict\n",
    "\n",
    "    def text_predict(self):\n",
    "        '''\n",
    "        音频批量转写，文本预测\n",
    "        '''\n",
    "        # 按照5s分割的音频列表\n",
    "        global segment_names\n",
    "        segment_names = self.split_wav_file()\n",
    "        # 二次切分 多线程\n",
    "        audio_files = self.list_split(segment_names)\n",
    "        # 文本转写\n",
    "        text_result_dict = self.ali_audio_rec(audio_files)\n",
    "        # 按照顺序取出文本\n",
    "        text_sorted_values = [value for _, value in sorted(text_result_dict.items())]\n",
    "        # 文本评测存储概率值和label\n",
    "        text_predict = self.text_predict(text_sorted_values)\n",
    "        return text_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7efd7351",
   "metadata": {},
   "outputs": [],
   "source": [
    "obj = text_audio_emo_predict('123.wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "965d3a23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "segmented_audio/segment_1.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\coding\\anaconda\\envs\\speechDemo\\lib\\site-packages\\sklearn\\base.py:306: UserWarning: Trying to unpickle estimator SVC from version 0.20.3 when using version 0.21.3. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "e:\\django_ai\\speech_ai\\login\\py\\EGG\\train.py:33: FutureWarning: Pass y=[0.         0.         0.         ... 0.06002045 0.10360317 0.07722206], sr=22050 as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mfcc_feature = librosa.feature.mfcc(y, sr, n_mfcc=16)\n",
      "e:\\django_ai\\speech_ai\\login\\py\\EGG\\train.py:36: FutureWarning: Pass y=[0.         0.         0.         ... 0.06002045 0.10360317 0.07722206] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  energy_feature = librosa.feature.rms(y)\n",
      "e:\\django_ai\\speech_ai\\login\\py\\EGG\\train.py:37: FutureWarning: Pass y=[0.         0.         0.         ... 0.06002045 0.10360317 0.07722206] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  rms_feature = librosa.feature.rms(y)\n"
     ]
    }
   ],
   "source": [
    "result = obj.total_predict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "10dcd634",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['neutral', 0.9862303137779236],\n",
       " ['negative', 0.9811258316040039],\n",
       " ['negative', 0.5116545557975769],\n",
       " ['neutral', 0.8026337623596191],\n",
       " ['positive', 0.9473720192909241],\n",
       " ['neutral', 0.8356102108955383],\n",
       " ['neutral', 0.6132266521453857],\n",
       " ['neutral', 0.5897694826126099],\n",
       " ['negative', 0.997803270816803],\n",
       " ['neutral', 0.9567863345146179],\n",
       " ['negative', 0.9974313378334045],\n",
       " ['negative', 0.9747483134269714],\n",
       " ['positive', 0.9800559878349304],\n",
       " ['neutral', 0.9857818484306335]]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "652be1d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['happy', 0.6780028163114433]]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5c968434",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([['neutral', 0.9862303137779236],\n",
       "  ['negative', 0.9811258316040039],\n",
       "  ['negative', 0.5116545557975769],\n",
       "  ['neutral', 0.8026337623596191],\n",
       "  ['positive', 0.9473720192909241],\n",
       "  ['neutral', 0.8356102108955383],\n",
       "  ['neutral', 0.6132266521453857],\n",
       "  ['neutral', 0.5897694826126099],\n",
       "  ['negative', 0.997803270816803],\n",
       "  ['neutral', 0.9567863345146179],\n",
       "  ['negative', 0.9974313378334045],\n",
       "  ['negative', 0.9747483134269714],\n",
       "  ['positive', 0.9800559878349304],\n",
       "  ['neutral', 0.9857818484306335]],\n",
       " [['happy', 0.6780028163114433]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d23d6d17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "segmented_audio/segment_11.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\coding\\anaconda\\envs\\speechDemo\\lib\\site-packages\\sklearn\\base.py:306: UserWarning: Trying to unpickle estimator SVC from version 0.20.3 when using version 0.21.3. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "e:\\django_ai\\speech_ai\\login\\py\\EGG\\train.py:33: FutureWarning: Pass y=[-0.09346106 -0.10721543 -0.04433772 ...  0.12077729  0.12267108\n",
      "  0.07469185], sr=22050 as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mfcc_feature = librosa.feature.mfcc(y, sr, n_mfcc=16)\n",
      "e:\\django_ai\\speech_ai\\login\\py\\EGG\\train.py:36: FutureWarning: Pass y=[-0.09346106 -0.10721543 -0.04433772 ...  0.12077729  0.12267108\n",
      "  0.07469185] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  energy_feature = librosa.feature.rms(y)\n",
      "e:\\django_ai\\speech_ai\\login\\py\\EGG\\train.py:37: FutureWarning: Pass y=[-0.09346106 -0.10721543 -0.04433772 ...  0.12077729  0.12267108\n",
      "  0.07469185] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  rms_feature = librosa.feature.rms(y)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[['neutral', 0.2968956199384202]]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obj.audio_predict(['segmented_audio/segment_11.wav'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "65717156",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = ['E:\\\\django_ai\\\\speech_ai\\\\login\\\\py\\\\EGG\\\\segmented_audio\\\\segment_1.wav',\n",
    " 'E:\\\\django_ai\\\\speech_ai\\\\login\\\\py\\\\EGG\\\\segmented_audio\\\\segment_10.wav',\n",
    " 'E:\\\\django_ai\\\\speech_ai\\\\login\\\\py\\\\EGG\\\\segmented_audio\\\\segment_11.wav',\n",
    " 'E:\\\\django_ai\\\\speech_ai\\\\login\\\\py\\\\EGG\\\\segmented_audio\\\\segment_12.wav',\n",
    " 'E:\\\\django_ai\\\\speech_ai\\\\login\\\\py\\\\EGG\\\\segmented_audio\\\\segment_13.wav',\n",
    " 'E:\\\\django_ai\\\\speech_ai\\\\login\\\\py\\\\EGG\\\\segmented_audio\\\\segment_14.wav',\n",
    " 'E:\\\\django_ai\\\\speech_ai\\\\login\\\\py\\\\EGG\\\\segmented_audio\\\\segment_2.wav',\n",
    " 'E:\\\\django_ai\\\\speech_ai\\\\login\\\\py\\\\EGG\\\\segmented_audio\\\\segment_3.wav',\n",
    " 'E:\\\\django_ai\\\\speech_ai\\\\login\\\\py\\\\EGG\\\\segmented_audio\\\\segment_4.wav',\n",
    " 'E:\\\\django_ai\\\\speech_ai\\\\login\\\\py\\\\EGG\\\\segmented_audio\\\\segment_5.wav',\n",
    " 'E:\\\\django_ai\\\\speech_ai\\\\login\\\\py\\\\EGG\\\\segmented_audio\\\\segment_6.wav',\n",
    " 'E:\\\\django_ai\\\\speech_ai\\\\login\\\\py\\\\EGG\\\\segmented_audio\\\\segment_7.wav',\n",
    " 'E:\\\\django_ai\\\\speech_ai\\\\login\\\\py\\\\EGG\\\\segmented_audio\\\\segment_8.wav',\n",
    " 'E:\\\\django_ai\\\\speech_ai\\\\login\\\\py\\\\EGG\\\\segmented_audio\\\\segment_9.wav']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "efa3804c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E:\\django_ai\\speech_ai\\login\\py\\EGG\\segmented_audio\\segment_1.wav\n",
      "你循环了吗\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\coding\\anaconda\\envs\\speechDemo\\lib\\site-packages\\sklearn\\base.py:306: UserWarning: Trying to unpickle estimator SVC from version 0.20.3 when using version 0.21.3. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "e:\\django_ai\\speech_ai\\login\\py\\EGG\\train.py:33: FutureWarning: Pass y=[0.         0.         0.         ... 0.06002045 0.10360317 0.07722206], sr=22050 as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mfcc_feature = librosa.feature.mfcc(y, sr, n_mfcc=16)\n",
      "e:\\django_ai\\speech_ai\\login\\py\\EGG\\train.py:36: FutureWarning: Pass y=[0.         0.         0.         ... 0.06002045 0.10360317 0.07722206] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  energy_feature = librosa.feature.rms(y)\n",
      "e:\\django_ai\\speech_ai\\login\\py\\EGG\\train.py:37: FutureWarning: Pass y=[0.         0.         0.         ... 0.06002045 0.10360317 0.07722206] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  rms_feature = librosa.feature.rms(y)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[['happy', 0.6780028163114433]]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obj.audio_predict(test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SpeechDemo",
   "language": "python",
   "name": "speechdemo"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
